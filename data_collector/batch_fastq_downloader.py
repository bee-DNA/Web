#!/usr/bin/env python3
"""
Robust FASTQ batch downloader
ç©©å®šçš„æ‰¹é‡FASTQä¸‹è¼‰å™¨
"""

import subprocess
import os
import sys
import time
import json
import signal
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# å…¨å±€ä¸­æ–·æ¨™èªŒ
interrupt_flag = False

def signal_handler(signum, frame):
    """è™•ç† Ctrl+C ä¸­æ–·ä¿¡è™Ÿ"""
    global interrupt_flag
    print("\n\nâš ï¸  æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨å®‰å…¨åœæ­¢...")
    print("â¸ï¸  ç­‰å¾…ç•¶å‰ä»»å‹™å®Œæˆå¾Œé€€å‡º...")
    interrupt_flag = True


def run_sra_command_with_timer(sra_bin, command, args, timeout=3600):
    """åŸ·è¡ŒSRAå‘½ä»¤ä¸¦é¡¯ç¤ºå³æ™‚ç§’æ•¸"""
    import threading

    executable = sra_bin / f"{command}.exe"
    cmd = [str(executable)] + args

    start_time = time.time()
    completed = False

    def show_timer():
        while not completed:
            elapsed = int(time.time() - start_time)
            print(f"\r  åŸ·è¡Œä¸­... {elapsed}ç§’", end="", flush=True)
            time.sleep(1)

    # å•Ÿå‹•è¨ˆæ™‚å™¨ç·šç¨‹
    timer_thread = threading.Thread(target=show_timer, daemon=True)
    timer_thread.start()

    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=timeout,
            encoding="utf-8",
            errors="ignore",
        )
        completed = True
        time.sleep(0.1)  # ç­‰å¾…è¨ˆæ™‚å™¨ç·šç¨‹æ›´æ–°
        print("\r", end="")  # æ¸…é™¤è¨ˆæ™‚å™¨é¡¯ç¤º
        return result.returncode == 0, result.stdout, result.stderr
    except subprocess.TimeoutExpired:
        completed = True
        time.sleep(0.1)
        print("\r", end="")
        return False, "", f"Timeout after {timeout}s"
    except Exception as e:
        completed = True
        time.sleep(0.1)
        print("\r", end="")
        return False, "", str(e)


def run_sra_command(sra_bin, command, args, timeout=3600):
    """åŸ·è¡ŒSRAå‘½ä»¤(ç„¡è¨ˆæ™‚å™¨ç‰ˆæœ¬)"""
    executable = sra_bin / f"{command}.exe"
    cmd = [str(executable)] + args

    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=timeout,
            encoding="utf-8",
            errors="ignore",
        )
        return result.returncode == 0, result.stdout, result.stderr
    except subprocess.TimeoutExpired:
        return False, "", f"Timeout after {timeout}s"
    except Exception as e:
        return False, "", str(e)


def download_fastq(run_id, sra_bin, output_dir, progress_data, base_dir):
    """ä¸‹è¼‰å–®å€‹FASTQ"""
    global interrupt_flag
    
    # æª¢æŸ¥ä¸­æ–·æ¨™èªŒ
    if interrupt_flag:
        print(f"\nâ¸ï¸  è·³é {run_id} (ç”¨æˆ¶ä¸­æ–·)")
        return False
    
    print(f"\n{'='*60}")
    print(f"ğŸ“¥ è™•ç†: {run_id}")
    print(f"{'='*60}")

    # æª¢æŸ¥æ˜¯å¦å·²å®Œæˆ
    if run_id in progress_data.get("completed", []):
        print(f"âœ… å·²å®Œæˆï¼Œè·³é")
        return True

    start_time = time.time()

    # Step 1: prefetch (ä¸‹è¼‰åˆ° OneDrive è‡¨æ™‚ç›®éŒ„)
    print(f"  æ­¥é©Ÿ 1/4: prefetch {run_id}...")
    step1_start = time.time()
    success, stdout, stderr = run_sra_command_with_timer(
        sra_bin, "prefetch", [run_id, "--max-size", "100G"], timeout=7200  # 120åˆ†é˜è¶…æ™‚
    )
    step1_time = time.time() - step1_start

    if not success:
        print(f" âŒ å¤±æ•— ({step1_time:.1f}ç§’)")
        print(f"  éŒ¯èª¤: {stderr[:100]}")
        progress_data["failed"].append(
            {
                "run_id": run_id,
                "step": "prefetch",
                "error": stderr[:200],
                "time": datetime.now().isoformat(),
            }
        )
        save_progress(progress_data)
        return False

    print(f"  âœ… å®Œæˆ ({step1_time:.1f}ç§’)")

    # Step 2: fasterq-dump (è§£å£“åˆ° E:\fastq_data)
    print(f"  æ­¥é©Ÿ 2/4: fasterq-dump {run_id}...")
    step2_start = time.time()
    success, stdout, stderr = run_sra_command_with_timer(
        sra_bin,
        "fasterq-dump",
        [run_id, "-O", str(output_dir), "--split-files"],
        timeout=9000,  # 150åˆ†é˜è¶…æ™‚
    )
    step2_time = time.time() - step2_start

    if not success:
        print(f"  âŒ å¤±æ•— ({step2_time:.1f}ç§’)")
        print(f"  éŒ¯èª¤: {stderr[:100]}")
        progress_data["failed"].append(
            {
                "run_id": run_id,
                "step": "fasterq-dump",
                "error": stderr[:200],
                "time": datetime.now().isoformat(),
            }
        )
        save_progress(progress_data)
        return False

    print(f"  âœ… å®Œæˆ ({step2_time:.1f}ç§’)")

    # æª¢æŸ¥ FASTQ æª”æ¡ˆ
    fastq_files = list(output_dir.glob(f"{run_id}*"))
    if not fastq_files:
        print(f"  âš ï¸  æ‰¾ä¸åˆ°è¼¸å‡ºæª”æ¡ˆ")
        return False

    total_size = sum(f.stat().st_size for f in fastq_files) / (1024 * 1024)

    print(f"  ğŸ“ FASTQ æª”æ¡ˆ: {len(fastq_files)} å€‹")
    print(f"  ğŸ’¾ å¤§å°: {total_size:.1f} MB")

    # Step 3: å‚™ä»½ SRA åˆ° E æ§½
    print(f"  æ­¥é©Ÿ 3/4: å‚™ä»½ SRA åˆ° E æ§½...", end="", flush=True)
    step3_start = time.time()
    sra_source = base_dir / run_id / f"{run_id}.sra"
    sra_backup_dir = Path("E:/sra_files") / run_id

    try:
        if sra_source.exists():
            sra_backup_dir.mkdir(parents=True, exist_ok=True)
            sra_dest = sra_backup_dir / f"{run_id}.sra"

            # è¤‡è£½ SRA æª”æ¡ˆåˆ° E æ§½
            import shutil

            shutil.copy2(sra_source, sra_dest)

            step3_time = time.time() - step3_start
            sra_size = sra_source.stat().st_size / (1024 * 1024)
            print(f" âœ… å®Œæˆ ({sra_size:.1f} MB, {step3_time:.1f}ç§’)")
        else:
            step3_time = time.time() - step3_start
            print(f" âš ï¸  æ‰¾ä¸åˆ° SRA æª”æ¡ˆ ({step3_time:.1f}ç§’)")
    except Exception as e:
        step3_time = time.time() - step3_start
        print(f" âš ï¸  è­¦å‘Š: {str(e)} ({step3_time:.1f}ç§’)")

    # Step 4: æ¸…ç† OneDrive è‡¨æ™‚è³‡æ–™å¤¾
    print(f"  æ­¥é©Ÿ 4/4: æ¸…ç†è‡¨æ™‚è³‡æ–™å¤¾...", end="", flush=True)
    step4_start = time.time()
    sra_temp_dir = base_dir / run_id

    try:
        if sra_temp_dir.exists():
            import shutil

            shutil.rmtree(sra_temp_dir)
            step4_time = time.time() - step4_start
            print(f" âœ… å®Œæˆ ({step4_time:.1f}ç§’)")
        else:
            step4_time = time.time() - step4_start
            print(f" âš ï¸  è³‡æ–™å¤¾ä¸å­˜åœ¨ ({step4_time:.1f}ç§’)")
    except Exception as e:
        step4_time = time.time() - step4_start
        print(f" âš ï¸  è­¦å‘Š: {str(e)} ({step4_time:.1f}ç§’)")

    elapsed = time.time() - start_time
    print(f"  â±ï¸  ç¸½æ™‚é–“: {elapsed:.1f} ç§’")

    progress_data["completed"].append(run_id)
    progress_data["total_size_mb"] = progress_data.get("total_size_mb", 0) + total_size

    # æ¯å®Œæˆä¸€å€‹å°±ä¿å­˜
    save_progress(progress_data)

    return True


def save_progress(progress_data):
    """ä¿å­˜é€²åº¦"""
    progress_file = Path(__file__).parent / "download_progress.json"
    progress_data["last_update"] = datetime.now().isoformat()

    with open(progress_file, "w", encoding="utf-8") as f:
        json.dump(progress_data, f, ensure_ascii=False, indent=2)


def load_progress():
    """è¼‰å…¥é€²åº¦"""
    progress_file = Path(__file__).parent / "download_progress.json"

    if progress_file.exists():
        try:
            with open(progress_file, "r", encoding="utf-8") as f:
                data = json.load(f)
                # ç¢ºä¿completedæ˜¯åˆ—è¡¨
                if "completed" in data and isinstance(data["completed"], list):
                    # è™•ç†èˆŠæ ¼å¼ï¼ˆdictï¼‰è½‰æ–°æ ¼å¼ï¼ˆstringï¼‰
                    data["completed"] = [
                        item["run_id"] if isinstance(item, dict) else item
                        for item in data["completed"]
                    ]
                return data
        except:
            pass

    return {
        "completed": [],
        "failed": [],
        "total_size_mb": 0,
        "start_time": datetime.now().isoformat(),
    }


def main():
    """ä¸»ç¨‹åº"""
    global interrupt_flag
    
    # è¨»å†Šä¿¡è™Ÿè™•ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    
    # è¨­å®šä¸¦è¡Œä¸‹è¼‰æ•¸é‡
    MAX_WORKERS = 10

    # è¨­å®šç’°å¢ƒè®Šæ•¸ï¼Œé¿å…OneDriveåŒæ­¥é–å®šå•é¡Œ
    os.environ["NCBI_HOME"] = "D:\\ncbi"
    os.environ["VDB_CONFIG"] = str(Path(__file__).parent / ".ncbirc")

    # è¨­å®šè·¯å¾‘
    base_dir = Path(__file__).parent
    sra_bin = base_dir / "sratoolkit.3.2.1-win64" / "bin"
    output_dir = Path("E:/fastq_data")  # æ”¹ç‚º E æ§½
    runs_file = base_dir / "runs.txt"

    # æª¢æŸ¥
    if not sra_bin.exists():
        print(f"âŒ SRA Toolkit ä¸å­˜åœ¨: {sra_bin}")
        return

    if not runs_file.exists():
        print(f"âŒ runs.txt ä¸å­˜åœ¨: {runs_file}")
        return

    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    output_dir.mkdir(parents=True, exist_ok=True)

    # è®€å–ä»»å‹™åˆ—è¡¨
    with open(runs_file, "r") as f:
        all_runs = [line.strip() for line in f if line.strip()]

    # è¼‰å…¥é€²åº¦
    progress_data = load_progress()

    completed = len(progress_data.get("completed", []))
    failed = len(progress_data.get("failed", []))
    total = len(all_runs)
    remaining = total - completed

    print(f"\n{'='*60}")
    print(f"ğŸš€ FASTQ æ‰¹é‡ä¸‹è¼‰å™¨")
    print(f"{'='*60}")
    print(f"  ç¸½ä»»å‹™: {total}")
    print(f"  å·²å®Œæˆ: {completed} ({completed/total*100:.1f}%)")
    print(f"  å¤±æ•—: {failed}")
    print(f"  å‰©é¤˜: {remaining}")
    print(f"  ä¸¦è¡Œæ•¸: {MAX_WORKERS}")
    print(f"  è¼¸å‡º: {output_dir}")
    print(f"{'='*60}\n")

    if remaining == 0:
        print("ğŸ‰ æ‰€æœ‰ä»»å‹™å·²å®Œæˆï¼")
        return

    # é–‹å§‹ä¸‹è¼‰
    success_count = 0
    fail_count = 0
    batch_start_time = time.time()
    processed_in_batch = 0
    lock = threading.Lock()

    # éæ¿¾å‡ºéœ€è¦è™•ç†çš„ä»»å‹™
    pending_runs = [
        run_id
        for run_id in all_runs
        if run_id not in progress_data.get("completed", [])
    ]

    # ä½¿ç”¨ä¸¦è¡Œä¸‹è¼‰
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # æäº¤æ‰€æœ‰ä»»å‹™
        future_to_run = {
            executor.submit(
                download_fastq, run_id, sra_bin, output_dir, progress_data, base_dir
            ): run_id
            for run_id in pending_runs
        }

        for future in as_completed(future_to_run):
            # æª¢æŸ¥ä¸­æ–·æ¨™èªŒ
            if interrupt_flag:
                print("\nâ¸ï¸  åœæ­¢æ¥æ”¶æ–°çµæœ...")
                break
                
            run_id = future_to_run[future]
            try:
                success = future.result()

                with lock:
                    if success:
                        success_count += 1
                        processed_in_batch += 1
                    else:
                        fail_count += 1

                    # è¨ˆç®—é ä¼°å‰©é¤˜æ™‚é–“
                    if processed_in_batch > 0:
                        elapsed_time = time.time() - batch_start_time
                        avg_time_per_item = elapsed_time / processed_in_batch
                        remaining_items = len(pending_runs) - processed_in_batch
                        estimated_seconds = avg_time_per_item * remaining_items

                        hours = int(estimated_seconds // 3600)
                        minutes = int((estimated_seconds % 3600) // 60)
                        seconds = int(estimated_seconds % 60)

                        if hours > 0:
                            eta_str = f"{hours}å°æ™‚{minutes}åˆ†é˜{seconds}ç§’"
                        elif minutes > 0:
                            eta_str = f"{minutes}åˆ†é˜{seconds}ç§’"
                        else:
                            eta_str = f"{seconds}ç§’"

                        print(
                            f"\n[{processed_in_batch}/{len(pending_runs)}] é€²åº¦: {processed_in_batch/len(pending_runs)*100:.1f}% | â±ï¸  é ä¼°å‰©é¤˜: {eta_str}"
                        )

                    # æ¯10å€‹é¡¯ç¤ºçµ±è¨ˆ
                    if processed_in_batch % 10 == 0:
                        current_completed = len(progress_data.get("completed", []))
                        current_failed = len(progress_data.get("failed", []))
                        total_size = progress_data.get("total_size_mb", 0)

                        elapsed_time = time.time() - batch_start_time
                        avg_time = (
                            elapsed_time / processed_in_batch
                            if processed_in_batch > 0
                            else 0
                        )

                        print(f"\n{'='*60}")
                        print(f"ğŸ“Š ä¸­æœŸå ±å‘Š [{processed_in_batch}/{total}]")
                        print(f"  æˆåŠŸ: {current_completed}")
                        print(f"  å¤±æ•—: {current_failed}")
                        print(
                            f"  ç¸½å¤§å°: {total_size:.1f} MB ({total_size/1024:.2f} GB)"
                        )
                        print(f"  å¹³å‡è™•ç†æ™‚é–“: {avg_time:.1f} ç§’/å€‹")
                        print(f"{'='*60}\n")

            except Exception as e:
                with lock:
                    fail_count += 1
                    print(f"\nâŒ è™•ç† {run_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    # æœ€çµ‚å ±å‘Š
    final_completed = len(progress_data.get("completed", []))
    final_failed = len(progress_data.get("failed", []))
    final_size = progress_data.get("total_size_mb", 0)

    print(f"\n{'='*60}")
    print(f"ğŸ‰ ä¸‹è¼‰å®Œæˆï¼")
    print(f"{'='*60}")
    print(f"  ç¸½ä»»å‹™: {total}")
    print(f"  æˆåŠŸ: {final_completed} ({final_completed/total*100:.1f}%)")
    print(f"  å¤±æ•—: {final_failed} ({final_failed/total*100:.1f}%)")
    print(f"  ç¸½å¤§å°: {final_size:.1f} MB ({final_size/1024:.2f} GB)")
    print(f"{'='*60}\n")

    if final_failed > 0:
        print("âŒ å¤±æ•—çš„ä»»å‹™:")
        for item in progress_data.get("failed", [])[-10:]:
            print(f"  - {item.get('run_id')}: {item.get('step')}")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        interrupt_flag = True
        print("\n\nâš ï¸  ä¸‹è¼‰è¢«ç”¨æˆ¶ä¸­æ–·")
        print("ğŸ’¾ é€²åº¦å·²ä¿å­˜åˆ° download_progress.json")
        print("ğŸ”„ ä¸‹æ¬¡åŸ·è¡Œå°‡å¾æ–·é»ç¹¼çºŒ")
    except Exception as e:
        print(f"\nâŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback

        traceback.print_exc()
